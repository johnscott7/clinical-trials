{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b71d99f",
   "metadata": {},
   "source": [
    "# 03 — Data Cleaning\n",
    "**ClinicalTrials.gov Dataset**  \n",
    "*Author: John Seaton*  \n",
    "*Last updated: 2025-12-14*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c6f03",
   "metadata": {},
   "source": [
    "## 1. Scope & Role of This Notebook\n",
    "\n",
    "**Project context:** This notebook performs a complete, systematic cleaning of the ClinicalTrials.gov dataset to prepare it for downstream analysis of global drug development patterns.\n",
    "\n",
    "**Data source:** ClinicalTrials.gov (public registry of clinical studies)  \n",
    "**Scope / time range:** This project uses the full available ClinicalTrials.gov dataset, covering the entire historical range of registered trials   \n",
    "**Primary key:** `NCT Number` (unique trial identifier used to link derived tables)\n",
    "\n",
    "**Inputs:**  \n",
    "- `data/raw/ClinicalTrials/ctg-studies.csv`\n",
    "\n",
    "**Outputs (written in Section 14):**  \n",
    "- `data/processed/clean_trials.csv` (trial-level cleaned dataset)  \n",
    "- `data/processed/clean_interventions.csv` (long-format interventions)  \n",
    "- `data/processed/clean_conditions.csv` (long-format conditions)  \n",
    "- `data/processed/clean_locations.csv` (long-format locations + extracted country)\n",
    "\n",
    "**Key filters / constraints:**  \n",
    "- The primary dataset is filtered to retain only trials containing **DRUG** and/or **BIOLOGICAL** interventions to focus analysis on drug development activity.\n",
    "\n",
    "**Goals:**   \n",
    "- Standardize critical fields such as trial phases, locations, date columns, interventions, conditions, and enrollment values\n",
    "- Resolve inconsistences arising from formatting differences, categorical variants and and grouped values\n",
    "- Handle missing, irregular, or redundant data using transparent and reproducible transformations\n",
    "- Engineer derived columns that improve analytical clarity and support futher exploratory or modeling efforts\n",
    "- Generate a fully cleaned, versioned dataset (CSV) for use in subsequent notebooks and pipeline stages\n",
    "\n",
    "All transformations in this notebook are documented, reproducible, and reversible.\n",
    "While new datasets are created through this notebook, the original raw dataset remains intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b27086",
   "metadata": {},
   "source": [
    "## 2. Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892d1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b69383",
   "metadata": {},
   "source": [
    "## 3. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf326f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530028, 22)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/ClinicalTrials/ctg-studies.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca8b73",
   "metadata": {},
   "source": [
    "## 4. High Level DataFrame Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6dec26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCT Number                     object\n",
       "Study Title                    object\n",
       "Study URL                      object\n",
       "Study Status                   object\n",
       "Conditions                     object\n",
       "Interventions                  object\n",
       "Primary Outcome Measures       object\n",
       "Secondary Outcome Measures     object\n",
       "Sponsor                        object\n",
       "Collaborators                  object\n",
       "Age                            object\n",
       "Phases                         object\n",
       "Enrollment                    float64\n",
       "Funder Type                    object\n",
       "Study Type                     object\n",
       "Study Design                   object\n",
       "Start Date                     object\n",
       "Primary Completion Date        object\n",
       "Completion Date                object\n",
       "First Posted                   object\n",
       "Locations                      object\n",
       "Study Documents                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9953805",
   "metadata": {},
   "source": [
    "Dates will need to be converted from object to datetime later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e2b6084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NCT Number',\n",
       " 'Study Title',\n",
       " 'Study URL',\n",
       " 'Study Status',\n",
       " 'Conditions',\n",
       " 'Interventions',\n",
       " 'Primary Outcome Measures',\n",
       " 'Secondary Outcome Measures',\n",
       " 'Sponsor',\n",
       " 'Collaborators',\n",
       " 'Age',\n",
       " 'Phases',\n",
       " 'Enrollment',\n",
       " 'Funder Type',\n",
       " 'Study Type',\n",
       " 'Study Design',\n",
       " 'Start Date',\n",
       " 'Primary Completion Date',\n",
       " 'Completion Date',\n",
       " 'First Posted',\n",
       " 'Locations',\n",
       " 'Study Documents']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show column names\n",
    "df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678626da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Study Documents               0.909578\n",
       "Collaborators                 0.675219\n",
       "Phases                        0.614666\n",
       "Secondary Outcome Measures    0.269754\n",
       "Interventions                 0.098470\n",
       "Locations                     0.081267\n",
       "Primary Completion Date       0.032085\n",
       "Primary Outcome Measures      0.025414\n",
       "Completion Date               0.023299\n",
       "Enrollment                    0.007309\n",
       "Conditions                    0.000006\n",
       "Study Status                  0.000000\n",
       "NCT Number                    0.000000\n",
       "Study Title                   0.000000\n",
       "Study URL                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# High-level missingness snapshot\n",
    "df.isna().mean().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb8cca6",
   "metadata": {},
   "source": [
    "The columns containing missing data will be addressed in the following ways:\n",
    "\n",
    "`Study Documents` (90.9% missing): Drop column. Not needed for analysis.\n",
    "\n",
    "`Collaborators` (67.5% missing): Drop column. Duplicative with Sponsor/Funder Type.\n",
    "\n",
    "`Phases` (61.5% missing): Keep column, leave missing values as-is. Missingness expected for observational studies.\n",
    "\n",
    "`Primary Outcome Measures` (23.3% missing) and `Secondary Outcome Measures` (27.0% missing): Drop these columns. Helpful but not essential data.\n",
    "\n",
    "`Interventions` (9.8% missing): Keep column. Investigate missing cases during cleaning. \n",
    "\n",
    "`Locations` (8.1% missing): Keep column. Investigate missing cases during cleaning. \n",
    "\n",
    "`Primary Completion Date` (3.2% missing) and `Completion Date` (2.3% missing): Keep one of these. Missing data likely from ongoing trials. \n",
    "\n",
    "`Enrollment` (0.7% missing): Keep column. Investigate missing cases during cleaning. \n",
    "\n",
    "There is a singular trial with missing Conditions data. This will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c60b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCT Number</th>\n",
       "      <th>Study Title</th>\n",
       "      <th>Study URL</th>\n",
       "      <th>Study Status</th>\n",
       "      <th>Conditions</th>\n",
       "      <th>Interventions</th>\n",
       "      <th>Primary Outcome Measures</th>\n",
       "      <th>Secondary Outcome Measures</th>\n",
       "      <th>Sponsor</th>\n",
       "      <th>Collaborators</th>\n",
       "      <th>...</th>\n",
       "      <th>Enrollment</th>\n",
       "      <th>Funder Type</th>\n",
       "      <th>Study Type</th>\n",
       "      <th>Study Design</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Primary Completion Date</th>\n",
       "      <th>Completion Date</th>\n",
       "      <th>First Posted</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Study Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>285416</th>\n",
       "      <td>NCT04730557</td>\n",
       "      <td>Reducing Obesity and Cartilage Compression in ...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT04730557</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>Obesity|Osteoarthritis|Knee Osteoarthritis</td>\n",
       "      <td>BEHAVIORAL: Weight Loss</td>\n",
       "      <td>Change from baseline in cartilage strain/thick...</td>\n",
       "      <td>Change from baseline in cartilage composition ...</td>\n",
       "      <td>Duke University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>88.0</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>INTERVENTIONAL</td>\n",
       "      <td>Allocation: RANDOMIZED|Intervention Model: PAR...</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>2023-10-26</td>\n",
       "      <td>2024-05-17</td>\n",
       "      <td>2021-01-29</td>\n",
       "      <td>Duke University Medical Center, Durham, North ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434463</th>\n",
       "      <td>NCT05603624</td>\n",
       "      <td>Effect of Sterile Versus Clean Gloves Intrapar...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT05603624</td>\n",
       "      <td>TERMINATED</td>\n",
       "      <td>Chorioamnionitis|Intrauterine Infection|Postpa...</td>\n",
       "      <td>PROCEDURE: Cervical examination to assess labor</td>\n",
       "      <td>Chorioamnionitis or intraamniotic or intrauter...</td>\n",
       "      <td>Postpartum endometritis, As defined by ACOG co...</td>\n",
       "      <td>Eastern Virginia Medical School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>INTERVENTIONAL</td>\n",
       "      <td>Allocation: RANDOMIZED|Intervention Model: PAR...</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>2022-11-02</td>\n",
       "      <td>Eastern Virginia Medical School, Norfolk, Virg...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191593</th>\n",
       "      <td>NCT04878627</td>\n",
       "      <td>Role of CBD in Regulating Meal Time Anxiety in...</td>\n",
       "      <td>https://clinicaltrials.gov/study/NCT04878627</td>\n",
       "      <td>ACTIVE_NOT_RECRUITING</td>\n",
       "      <td>Anorexia Nervosa</td>\n",
       "      <td>DRUG: Cannabidiol|DRUG: Placebo</td>\n",
       "      <td>Committee of Clinical Investigations UKU-Side ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of California, San Diego</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>INTERVENTIONAL</td>\n",
       "      <td>Allocation: RANDOMIZED|Intervention Model: PAR...</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>2026-06</td>\n",
       "      <td>2026-06</td>\n",
       "      <td>2021-05-07</td>\n",
       "      <td>University of California San Diego, San Diego,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         NCT Number                                        Study Title  \\\n",
       "285416  NCT04730557  Reducing Obesity and Cartilage Compression in ...   \n",
       "434463  NCT05603624  Effect of Sterile Versus Clean Gloves Intrapar...   \n",
       "191593  NCT04878627  Role of CBD in Regulating Meal Time Anxiety in...   \n",
       "\n",
       "                                           Study URL           Study Status  \\\n",
       "285416  https://clinicaltrials.gov/study/NCT04730557              COMPLETED   \n",
       "434463  https://clinicaltrials.gov/study/NCT05603624             TERMINATED   \n",
       "191593  https://clinicaltrials.gov/study/NCT04878627  ACTIVE_NOT_RECRUITING   \n",
       "\n",
       "                                               Conditions  \\\n",
       "285416         Obesity|Osteoarthritis|Knee Osteoarthritis   \n",
       "434463  Chorioamnionitis|Intrauterine Infection|Postpa...   \n",
       "191593                                   Anorexia Nervosa   \n",
       "\n",
       "                                          Interventions  \\\n",
       "285416                          BEHAVIORAL: Weight Loss   \n",
       "434463  PROCEDURE: Cervical examination to assess labor   \n",
       "191593                  DRUG: Cannabidiol|DRUG: Placebo   \n",
       "\n",
       "                                 Primary Outcome Measures  \\\n",
       "285416  Change from baseline in cartilage strain/thick...   \n",
       "434463  Chorioamnionitis or intraamniotic or intrauter...   \n",
       "191593  Committee of Clinical Investigations UKU-Side ...   \n",
       "\n",
       "                               Secondary Outcome Measures  \\\n",
       "285416  Change from baseline in cartilage composition ...   \n",
       "434463  Postpartum endometritis, As defined by ACOG co...   \n",
       "191593                                                NaN   \n",
       "\n",
       "                                    Sponsor Collaborators  ... Enrollment  \\\n",
       "285416                      Duke University           NaN  ...       88.0   \n",
       "434463      Eastern Virginia Medical School           NaN  ...      163.0   \n",
       "191593  University of California, San Diego           NaN  ...       40.0   \n",
       "\n",
       "       Funder Type      Study Type  \\\n",
       "285416       OTHER  INTERVENTIONAL   \n",
       "434463       OTHER  INTERVENTIONAL   \n",
       "191593       OTHER  INTERVENTIONAL   \n",
       "\n",
       "                                             Study Design  Start Date  \\\n",
       "285416  Allocation: RANDOMIZED|Intervention Model: PAR...  2020-06-05   \n",
       "434463  Allocation: RANDOMIZED|Intervention Model: PAR...  2021-09-02   \n",
       "191593  Allocation: RANDOMIZED|Intervention Model: PAR...  2022-01-20   \n",
       "\n",
       "       Primary Completion Date Completion Date First Posted  \\\n",
       "285416              2023-10-26      2024-05-17   2021-01-29   \n",
       "434463              2022-09-01      2022-09-01   2022-11-02   \n",
       "191593                 2026-06         2026-06   2021-05-07   \n",
       "\n",
       "                                                Locations Study Documents  \n",
       "285416  Duke University Medical Center, Durham, North ...             NaN  \n",
       "434463  Eastern Virginia Medical School, Norfolk, Virg...             NaN  \n",
       "191593  University of California San Diego, San Diego,...             NaN  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small sample of the starting dataframe\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f9561",
   "metadata": {},
   "source": [
    "## 5. Cleaning Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d62dc",
   "metadata": {},
   "source": [
    "This notebooks applies a series of cleaning steps to standardize the ClinicalTrials.gov dataframe for analysis. Key transformations include (in order): \n",
    "\n",
    "- converting all date fields to proper datetime format\n",
    "- dropping fields that are redundant or irrelevant for the analysis of drug development pipelines\n",
    "- normalizing categorical fields such as trial phases and funder types\n",
    "- parsing and classifying interventions\n",
    "- engineering a derived field for combined drug and biological interventions\n",
    "- cleaning and structuring the conditions and locations fields\n",
    "- verifying enrollment values\n",
    "- then exporting the final processed dataframes to CSVs\n",
    "\n",
    "Each transformation or cleaning step is applied sequentially below and documented for reproducability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f6462e",
   "metadata": {},
   "source": [
    "## 6. Standardize Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e06fd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all four data columns from object type to datetime format\n",
    "\n",
    "date_cols = ['Start Date', 'Primary Completion Date', 'Completion Date', 'First Posted']\n",
    "\n",
    "# Store raw string backups\n",
    "for col in date_cols:\n",
    "    df[f'{col} (raw)'] = df[col]\n",
    "\n",
    "# Convert to datetime\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    " # Add '15' (monthly-midpoint) to dates with missing day values to convert YYYY-MM to YYYY-MM-15\n",
    " # This standardizes date format for later analysis\n",
    "for col in date_cols:\n",
    "    raw_col = f'{col} (raw)'\n",
    "    \n",
    "    # Locate dates with YYYY-MM formatting\n",
    "    month_only = df[raw_col].astype(str).str.match(r'^\\d{4}-\\d{2}$')\n",
    "    \n",
    "    df.loc[month_only, col] = pd.to_datetime(df.loc[month_only, raw_col] + '-15',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1188a86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date                 datetime64[ns]\n",
      "Primary Completion Date    datetime64[ns]\n",
      "Completion Date            datetime64[ns]\n",
      "First Posted               datetime64[ns]\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirm dates have been coverted to datetime\n",
    "print(df[date_cols].dtypes)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "903dafae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Start Date                 0.000000\n",
       "Primary Completion Date    3.208510\n",
       "Completion Date            2.329877\n",
       "First Posted               0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check on missing date values after above transformations\n",
    "df[date_cols].isna().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "796e7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Completion Date: 17006 missing out of 530028 (3.21%)\n",
      "Completion Date: 12349 missing out of 530028 (2.33%)\n"
     ]
    }
   ],
   "source": [
    "# Convert % missing into absolute counts\n",
    "for col in ['Primary Completion Date', 'Completion Date']:\n",
    "    missing_count = df[col].isna().sum()\n",
    "    total = len(df)\n",
    "    print(f\"{col}: {missing_count} missing out of {total} \"\n",
    "          f\"({missing_count / total * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84f96fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Completion Date\n",
      "NaT           17006\n",
      "2025-12-31     3768\n",
      "2025-12-15     3116\n",
      "Name: count, dtype: int64\n",
      "Completion Date\n",
      "NaT           12349\n",
      "2025-12-31     4188\n",
      "2025-12-15     3307\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show the most common values in the Completion Date fields\n",
    "for col in ['Primary Completion Date', 'Completion Date']:\n",
    "    print(df[col].value_counts(dropna=False).head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbb25d",
   "metadata": {},
   "source": [
    "This validates that all remaining missing values for the Completion Date columns were missing in the original clinicaltrials.gov dataset, and were not created during the cleaning or conversion steps above. The missing values are relatively small (2-3%) and most likely represent the trials that are ongoing at the time the dataset was downloaded. The four date columns have been converted to datetime format, the YYYY-MM data values have been converted to YYYY-MM-15 format, and all remaining missing values in these columns are NaT (not a Time) and will be left as-is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2261c63",
   "metadata": {},
   "source": [
    "## 7. Dropping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07988a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530028, 26)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check existing dataframe shape before dropping columns\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e577b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Study Title', axis=1)\n",
    "df = df.drop('Study Status', axis=1)\n",
    "df = df.drop('Study URL', axis=1)\n",
    "df = df.drop('Study Documents', axis=1)\n",
    "df = df.drop('Primary Outcome Measures', axis=1)\n",
    "df = df.drop('Secondary Outcome Measures', axis=1)\n",
    "df = df.drop('Collaborators', axis=1)\n",
    "df = df.drop('Age', axis=1)\n",
    "df = df.drop('Completion Date', axis=1)\n",
    "df = df.drop('First Posted', axis=1)\n",
    "df = df.drop('Study Design', axis=1)\n",
    "# Drop raw date columns created earlier in section 6\n",
    "df = df.drop('First Posted (raw)', axis=1)\n",
    "df = df.drop('Start Date (raw)', axis=1)\n",
    "df = df.drop('Primary Completion Date (raw)', axis=1)\n",
    "df = df.drop('Completion Date (raw)', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101d846f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530028, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check existing dataframe shape after dropping columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b57eff41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NCT Number',\n",
       " 'Conditions',\n",
       " 'Interventions',\n",
       " 'Sponsor',\n",
       " 'Phases',\n",
       " 'Enrollment',\n",
       " 'Funder Type',\n",
       " 'Study Type',\n",
       " 'Start Date',\n",
       " 'Primary Completion Date',\n",
       " 'Locations']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show what columns remain\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9bbbb1",
   "metadata": {},
   "source": [
    "Eleven of the original fields were succesfully dropped from dataframe `df` due to their irrelevance to the primary analysis. There are now eleven columns remaining, and one more will be added in section 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ba96e",
   "metadata": {},
   "source": [
    "## 8. Clean and Normalize Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a0ed57",
   "metadata": {},
   "source": [
    "This section exists to identify categorical columns that require normalization and light cleaning (inconsistent casing, delimiter usage, or fields with multiple values). The goal is to ensure values are internally consistent within each field to ensure values are suitable for later analysis. Only light work is performed here in section 8, complex transformations are taken on later in sections dedicated to each field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "087aab75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Study Type            2\n",
       "Phases                7\n",
       "Funder Type           9\n",
       "Sponsor           46212\n",
       "Conditions       214914\n",
       "Locations        289919\n",
       "Interventions    396586\n",
       "NCT Number       530028\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Show most unique values for each category\n",
    "df.select_dtypes(include='object').nunique().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825a357f",
   "metadata": {},
   "source": [
    "Low cardinality categories (categories containing small number of unique elements in the set) that will be addressed here include Study Type, Age, Phases, and Funder Type. Remaining categories have a huge variety of unique elements, with values in the thousands. Let's investigate the unique elements in each of the four categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9722c18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Study Type\n",
       "INTERVENTIONAL    406244\n",
       "OBSERVATIONAL     123784\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Study Type'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabfcd6",
   "metadata": {},
   "source": [
    "No work to be done here, two unique values. Leaving as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5134cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phases\n",
       "NaN              325790\n",
       "PHASE2            59379\n",
       "PHASE1            44736\n",
       "PHASE3            39119\n",
       "PHASE4            33139\n",
       "PHASE1|PHASE2     15396\n",
       "PHASE2|PHASE3      6972\n",
       "EARLY_PHASE1       5497\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Phases'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8653518",
   "metadata": {},
   "source": [
    "The Phases column has some cases of combined values, such as Phase 1|Phase 2, which will causes issues with analysis. These combined values are scenarios where the trial phases are running concurrently. For the sake of this analysis, the trial phase will be conerted to the higher of the two values, i.e. Phase 1|Phase 2 --> Phase 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3cdae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the inconsistent values \n",
    "corrected_values = {'EARLY_PHASE1': 'PHASE1', 'PHASE1|PHASE2': 'PHASE2', 'PHASE2|PHASE3': 'PHASE3'}\n",
    "df['Phases'] = df['Phases'].replace(corrected_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c335ac23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Phases\n",
       "NaN       325790\n",
       "PHASE2     74775\n",
       "PHASE1     50233\n",
       "PHASE3     46091\n",
       "PHASE4     33139\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show corrected Phases values\n",
    "df['Phases'].value_counts(dropna=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aacbbb",
   "metadata": {},
   "source": [
    "The Phases column is now ready for further analysis. All combined and inconsistent lables were normalized to single phases. NaN values have been preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2413174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Funder Type\n",
       "OTHER        375118\n",
       "INDUSTRY     120900\n",
       "OTHER_GOV     13654\n",
       "NIH           10523\n",
       "NETWORK        4638\n",
       "FED            4572\n",
       "INDIV           550\n",
       "UNKNOWN          70\n",
       "AMBIG             3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show various values of Funder types\n",
    "df['Funder Type'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f61d527",
   "metadata": {},
   "source": [
    "The only normalization to be performed for the Funder Type category is to group miscellaneous columns such as Unknown and Ambig into Other. NIH, FED, and OTHER_GOV are all government agencies, but are distinct enough to warrant their own categories, and combining them would erase structure. NETWORK represents research networks (distinct from governemnt) and will also be left as-is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24117209",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Funder Type'] = df['Funder Type'].replace({'INDIV': 'OTHER', 'UNKNOWN': 'OTHER', 'AMBIG': 'OTHER'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cdfc93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Funder Type\n",
       "OTHER        375741\n",
       "INDUSTRY     120900\n",
       "OTHER_GOV     13654\n",
       "NIH           10523\n",
       "NETWORK        4638\n",
       "FED            4572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show cleaned values of Funder types\n",
    "df['Funder Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d8cd6",
   "metadata": {},
   "source": [
    "## 9. Interventions Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65671b",
   "metadata": {},
   "source": [
    "Clinical trials frequently include multiple interventions, and analyzing at an intervention level (for example, answering which drugs and biologicals are studied across the most trials) becomes unreliable when storing multiple interventions in a single trial-level field in the `df` dataframe. To address this, interventions are separated on the vertical bar delimiter (|) and normalized into a separate intervention-levell, long format dataframe (`long_inter_df`) where each intervention is given its own row and linked back to the original clinical trial via the NCT Number. This transformation allows interventions to be parsed and re-classified reliably while preserving the one-to-many relationship between trials and interventions, rather than forcing multiple interventions into a single trial row.\n",
    "\n",
    "After establishing the long format dataframe, the analysis aggregates back to the clinical trial level to create boolean indicator columns (has_drug, has_biological, has_drug_or_biological) that identify whether a clinical trial includes at least one drug or biological intervention. The column has_drug_or_biological and its boolean values are then used to then filter the original dataframe `df` down to only the clinical trials relevant to a study of drug development (those containing at least one DRUG or BIOLOGICAL intervention). All clinical trial rows not containing either a DRUG or BIOLOGICAL intervention are dropped, and the temporary columns created for this purpose (has_drug, has-biological, has_drug_or_biological) are subsequently removed.\n",
    "\n",
    "Together, these steps produce two complementary dataframes: a cleaned trial-level dataframe (`df`) used for trial-based analysis and a normalized intervention-level dataframe (`long_inter_df`) used for intervention analysis (e.g., identifying which drugs or biologicals are studied most frequently). This process significantly reduces the size of the original df dataframe and also preserves the detailed intervention structure required for downstream analysis through the creation of long_inter_df. This process represents the most critical transformation step in the overall analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a38d0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(530028, 11)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current dataframe shape, for comparison at end of section\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edcf0991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391069    DIETARY_SUPPLEMENT: with Flavanol|DIETARY_SUPP...\n",
       "79298     DRUG: IMC-001 and Optimal medical treatment|DR...\n",
       "370299                                                  NaN\n",
       "383029                  DRUG: Methylphenidate|DRUG: Placebo\n",
       "245975            BEHAVIORAL: Access to sedentary behaviors\n",
       "276916      DIETARY_SUPPLEMENT: L. paracasei fermented milk\n",
       "513093                  PROCEDURE: Truwiev PCD laryngoscope\n",
       "Name: Interventions, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reveal a small sample of current Intervention data formatting\n",
    "df['Interventions'].sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45ea721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Interventions column based on the vertical bar delimiter ( | )\n",
    "long_inter_df = df[['NCT Number', 'Interventions']].copy()\n",
    "\n",
    "long_inter_df['Interventions'] = (\n",
    "    long_inter_df['Interventions']\n",
    "    .fillna('')\n",
    "    .str.replace(r'\\s*\\|\\s*', '|', regex=True)  # normalize spacing around the delimiter\n",
    "    .str.split('|')\n",
    ")\n",
    "\n",
    "long_inter_df = long_inter_df.explode('Interventions')\n",
    "long_inter_df['Interventions'] = long_inter_df['Interventions'].str.strip()\n",
    "long_inter_df = long_inter_df[long_inter_df['Interventions'] != '']  # drop empty pieces\n",
    "\n",
    "\n",
    "pattern = r'^\\s*([A-Z_]+)\\s*:\\s*(.*)$'  # Regex, detailed explanation below:\n",
    "# r'' defines the scope of what pandas is looking at (raw string)\n",
    "# ^: Defines where regex should start matching from\n",
    "# \\s*: This allows for spaces, where \\s defines a space and * defines potential multiples\n",
    "# ([A-Z_]+) Begins capturing with an uppercase letter or underscore, and the + means one or more\n",
    "# \\s once again allows for a space after the intervention class but before the colon\n",
    "# : matches the colon from the intervention column\n",
    "# \\s once again allows for a space, this time after the colon\n",
    "# (.*) tells regex to capture everything it finds after the colon\n",
    "# $ ends the string\n",
    "\n",
    "long_inter_df[['Intervention_Class', 'Intervention_Name']] = long_inter_df['Interventions'].str.extract(pattern)\n",
    "long_inter_df['Intervention_Name'] = long_inter_df['Intervention_Name'].str.strip()\n",
    "\n",
    "# normalize class text (handles weird casing/spaces)\n",
    "long_inter_df['Intervention_Class'] = long_inter_df['Intervention_Class'].str.strip().str.upper()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "723b1e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in new dataframe long_inter_df: 901606\n",
      "Rows with null value Interventions after extraction attempt: 184\n",
      "Percent of Interventions that failed extraction: 0.02 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Interventions\n",
       "OTHER              147\n",
       "DEVICE               3\n",
       "DIAGNOSTIC_TEST      3\n",
       "PROCEDURE            3\n",
       "GENETIC              2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine how many trial Interventions were unable to be extracted using regex in the above code block\n",
    "\n",
    "failed_ext = long_inter_df['Intervention_Class'].isna()\n",
    "\n",
    "print('Rows in new dataframe long_inter_df:', len(long_inter_df))\n",
    "print('Rows with null value Interventions after extraction attempt:', failed_ext.sum())\n",
    "print('Percent of Interventions that failed extraction:', round(100 * failed_ext.mean(), 2), '%')\n",
    "\n",
    "# Value counts for unmatched value types\n",
    "(long_inter_df.loc[failed_ext, 'Interventions'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a36fc4",
   "metadata": {},
   "source": [
    "The above output shows the regex extraction for Intervention (from dataframe `df` to dataframe `long_inter_df`) was successful at a rate of 99.98%. Remaining uncaptured Interventions are not clustered around DRUG or BIOLOGICAL, are inconsequentially small, and will therefore be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc2a1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where Intervention extraction failed\n",
    "long_inter_df = long_inter_df.dropna(subset=['Intervention_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42cd673b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "901422"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the rows were dropped by comparing number of rows against the value output before the drop (901,606)\n",
    "len(long_inter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50d2057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jseat\\AppData\\Local\\Temp\\ipykernel_28180\\778796617.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['has_drug_or_biological'] = df['has_drug_or_biological'].fillna(False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "# Identify trials with DRUG or BIOLOGICAL interventions\n",
    "has_drug_or_bio = (long_inter_df['Intervention_Class'].isin(['DRUG', 'BIOLOGICAL'])\n",
    "    .groupby(long_inter_df['NCT Number']).any()\n",
    "    .rename('has_drug_or_biological').reset_index())\n",
    "\n",
    "# Merge back onto the primary dataframe df\n",
    "df = df.merge(has_drug_or_bio, on='NCT Number', how='left') # Left merge\n",
    "\n",
    "# Assign the trials with no drug and no biological interventions a false boolean value\n",
    "df['has_drug_or_biological'] = df['has_drug_or_biological'].fillna(False).astype(bool)\n",
    "\n",
    "# Keep only trials with DRUG or BIOLOGICAL interventions\n",
    "df = df[df['has_drug_or_biological']].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9c8772",
   "metadata": {},
   "source": [
    "While Intervention analysis can now be performed using the `long_inter_df` table, trial based analysis requires preserving a single row per clinical trial, as seen in the original dataframe `df`. The below code will aggregate drug and biological intervention names back to the trial level to support filtering out non-drug and non-biological trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80237a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table that has all DRUG and BIOLOGICAL names for each trial\n",
    "drug_bio_names = (\n",
    "    long_inter_df.loc[long_inter_df['Intervention_Class'].isin(['DRUG', 'BIOLOGICAL'])]\n",
    "    .groupby('NCT Number')['Intervention_Name']\n",
    "    .apply(lambda s: sorted(set(s.dropna()))) # Condense the drug/bio name rows into one list per trial\n",
    "    .reset_index(name='drug_bio_interventions')\n",
    ")\n",
    "\n",
    "# Left merge the intervention names back to the primary dataframe df using NCT Number as the key\n",
    "df = df.merge(drug_bio_names, on='NCT Number', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3935a369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196212    [CD0271 0.1%/CD1579 2.5% gel, CD0271 0.1%/CD15...\n",
       "94625                                    [Allopregnanolone]\n",
       "47536                   [0.5% 5-fluorouracil normal saline]\n",
       "178946    [fluorouracil, gemcitabine hydrochloride, leuc...\n",
       "20359                                  [Placebo, Prasugrel]\n",
       "50004                                            [AndroGel]\n",
       "155002                                 [LC51-0255, Placebo]\n",
       "113577                               [Control, Remimazolam]\n",
       "61834                                          [Radafaxine]\n",
       "44504     [Azithromycin Capsule, Doxycycline Capsule, Pl...\n",
       "151983    [cytarabine, decitabine, omacetaxine mepesucci...\n",
       "Name: drug_bio_interventions, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show sample values from newly created column\n",
    "df['drug_bio_interventions'].sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f655b241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_drug_or_biological\n",
       "True    211771\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the newly created column \n",
    "df['has_drug_or_biological'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90eb5a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drug_bio_interventions\n",
       "1     96544\n",
       "2     76398\n",
       "3     21188\n",
       "4      9401\n",
       "5      3555\n",
       "6      2019\n",
       "7       991\n",
       "8       613\n",
       "9       317\n",
       "10      223\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show how many trials have various numbers of drug/biological interventions\n",
    "df['drug_bio_interventions'].apply(len).value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b1f9fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCT Number</th>\n",
       "      <th>Interventions</th>\n",
       "      <th>Intervention_Class</th>\n",
       "      <th>Intervention_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>375691</th>\n",
       "      <td>NCT02665572</td>\n",
       "      <td>BEHAVIORAL: bladder recycling</td>\n",
       "      <td>BEHAVIORAL</td>\n",
       "      <td>bladder recycling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338518</th>\n",
       "      <td>NCT04038008</td>\n",
       "      <td>DRUG: Diflucan®</td>\n",
       "      <td>DRUG</td>\n",
       "      <td>Diflucan®</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315324</th>\n",
       "      <td>NCT06283355</td>\n",
       "      <td>BIOLOGICAL: Nasal Microbiota Transplant (NMT)</td>\n",
       "      <td>BIOLOGICAL</td>\n",
       "      <td>Nasal Microbiota Transplant (NMT)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NCT Number                                  Interventions  \\\n",
       "375691  NCT02665572                  BEHAVIORAL: bladder recycling   \n",
       "338518  NCT04038008                                DRUG: Diflucan®   \n",
       "315324  NCT06283355  BIOLOGICAL: Nasal Microbiota Transplant (NMT)   \n",
       "\n",
       "       Intervention_Class                  Intervention_Name  \n",
       "375691         BEHAVIORAL                  bladder recycling  \n",
       "338518               DRUG                          Diflucan®  \n",
       "315324         BIOLOGICAL  Nasal Microbiota Transplant (NMT)  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small sample of the new dataframe\n",
    "long_inter_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2112978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCT Number</th>\n",
       "      <th>Conditions</th>\n",
       "      <th>Interventions</th>\n",
       "      <th>Sponsor</th>\n",
       "      <th>Phases</th>\n",
       "      <th>Enrollment</th>\n",
       "      <th>Funder Type</th>\n",
       "      <th>Study Type</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Primary Completion Date</th>\n",
       "      <th>Locations</th>\n",
       "      <th>has_drug_or_biological</th>\n",
       "      <th>drug_bio_interventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>NCT00003449</td>\n",
       "      <td>Ovarian Cancer</td>\n",
       "      <td>DRUG: dexamethasone|DRUG: gemcitabine hydrochl...</td>\n",
       "      <td>University of Southern California</td>\n",
       "      <td>PHASE2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>INTERVENTIONAL</td>\n",
       "      <td>1998-05-15</td>\n",
       "      <td>2002-06-15</td>\n",
       "      <td>USC/Norris Comprehensive Cancer Center and Hos...</td>\n",
       "      <td>True</td>\n",
       "      <td>[dexamethasone, gemcitabine hydrochloride, pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59031</th>\n",
       "      <td>NCT00711607</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>DRUG: nomegestrol acetate and estradiol</td>\n",
       "      <td>Organon and Co</td>\n",
       "      <td>PHASE1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>INDUSTRY</td>\n",
       "      <td>INTERVENTIONAL</td>\n",
       "      <td>2007-05-01</td>\n",
       "      <td>2007-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[nomegestrol acetate and estradiol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187013</th>\n",
       "      <td>NCT01638208</td>\n",
       "      <td>Irritable Bowel Syndrome</td>\n",
       "      <td>DRUG: VSL#3</td>\n",
       "      <td>Asian Institute of Gastroenterology, India</td>\n",
       "      <td>PHASE4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>INTERVENTIONAL</td>\n",
       "      <td>2012-08-15</td>\n",
       "      <td>2012-12-15</td>\n",
       "      <td>Asian Institute of Gstroenterology, Hyderabad,...</td>\n",
       "      <td>True</td>\n",
       "      <td>[VSL#3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NCT Number                Conditions  \\\n",
       "5177    NCT00003449            Ovarian Cancer   \n",
       "59031   NCT00711607                   Healthy   \n",
       "187013  NCT01638208  Irritable Bowel Syndrome   \n",
       "\n",
       "                                            Interventions  \\\n",
       "5177    DRUG: dexamethasone|DRUG: gemcitabine hydrochl...   \n",
       "59031             DRUG: nomegestrol acetate and estradiol   \n",
       "187013                                        DRUG: VSL#3   \n",
       "\n",
       "                                           Sponsor  Phases  Enrollment  \\\n",
       "5177             University of Southern California  PHASE2        35.0   \n",
       "59031                               Organon and Co  PHASE1        25.0   \n",
       "187013  Asian Institute of Gastroenterology, India  PHASE4        40.0   \n",
       "\n",
       "       Funder Type      Study Type Start Date Primary Completion Date  \\\n",
       "5177         OTHER  INTERVENTIONAL 1998-05-15              2002-06-15   \n",
       "59031     INDUSTRY  INTERVENTIONAL 2007-05-01              2007-09-01   \n",
       "187013       OTHER  INTERVENTIONAL 2012-08-15              2012-12-15   \n",
       "\n",
       "                                                Locations  \\\n",
       "5177    USC/Norris Comprehensive Cancer Center and Hos...   \n",
       "59031                                                 NaN   \n",
       "187013  Asian Institute of Gstroenterology, Hyderabad,...   \n",
       "\n",
       "        has_drug_or_biological  \\\n",
       "5177                      True   \n",
       "59031                     True   \n",
       "187013                    True   \n",
       "\n",
       "                                   drug_bio_interventions  \n",
       "5177    [dexamethasone, gemcitabine hydrochloride, pac...  \n",
       "59031                 [nomegestrol acetate and estradiol]  \n",
       "187013                                            [VSL#3]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small sample of primary dataframe df with new columns\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5929a92",
   "metadata": {},
   "source": [
    "Of  all clinical trials included in the ClinicalTrials.gov dataset, approximately 211,000 (~45%) of them contain Drug or Biological Interventions. The remainder will now be dropped from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04b5a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['has_drug_or_biological'] = (df['has_drug_or_biological'].fillna(False).astype('boolean')) # Define any trials with missing Intervention data a value of False in the 'has_drug_or_biological' column.\n",
    "df = df[df['has_drug_or_biological']] # Drop all trials without Drug or Biological Interventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f337e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['has_drug_or_biological']) # Drop columns that were created for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2309d0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211771, 12)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show new dataframe shape now that only drug and biological trials remain\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea98d4",
   "metadata": {},
   "source": [
    "Value of 211,711 matches the output from cell 38. `df` successfully updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18e3fbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    477836.00\n",
       "mean          1.89\n",
       "std           1.39\n",
       "min           1.00\n",
       "25%           1.00\n",
       "50%           2.00\n",
       "75%           2.00\n",
       "max          97.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary statistics on number of interventions per trial\n",
    "long_inter_df.groupby('NCT Number').size().describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9cc6d",
   "metadata": {},
   "source": [
    "There now exists two dataframes for this clinical trial analysis. The original dataframe `df` has been reduced to 211,711 trials, all of which contain drug and/or biological interventions, and will be used for trial-level analysis. The newly created dataframe `long_inter_df` will be used to perform data analysis on the various biological and drug types studied across the clinical trials dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "69c07c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip Interventions of whitespaces and transform to lowercase\n",
    "long_inter_df['Interventions'] = (long_inter_df['Interventions'].str.strip().str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b44157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interventions\n",
       "drug: placebo                           27576\n",
       "other: placebo                           6900\n",
       "other: laboratory biomarker analysis     3105\n",
       "dietary_supplement: placebo              2915\n",
       "drug: cyclophosphamide                   2818\n",
       "other: no intervention                   2251\n",
       "drug: cisplatin                          2225\n",
       "drug: carboplatin                        2211\n",
       "drug: paclitaxel                         2082\n",
       "drug: dexamethasone                      1997\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate what the top interventions are across clinical trials\n",
    "top_interventions = (long_inter_df['Interventions'].value_counts().head(10))\n",
    "\n",
    "top_interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb293e8",
   "metadata": {},
   "source": [
    "The above output of the top ten interventions across all clinical trials reveals there are times where we see a single intervention repeated across mutliple classes, such as Placebo appearing as a DRUG, BIOLOGICAL, and DIETARY_SUPPLEMENT. Because of this, raw string-level counts at this stage mix together classification differences and should not be interpreted as accurate counts of intervention.\n",
    "\n",
    "In the 04_analysis notebook, Interventions will be explicitly filtered by class using the long_inter_df table, where classification can be handled explicitly. This allows unique intervention types (e.g. Placebo) to be counted together when appearing under different classes in different trials. This approach avoids losing information during cleaning while allowing intervention counts to be interpreted correctly during analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e226d41",
   "metadata": {},
   "source": [
    "## 10. Conditions Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6116c80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm missingness\n",
    "df['Conditions'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74288c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the single trial missing Condition data\n",
    "df = df.dropna(subset=['Conditions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b4c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141717                            Breast Cancer\n",
       "75357                       Alzheimer's Disease\n",
       "52430                  KRAS Mutant Solid Tumors\n",
       "122817                        Prostatic Adenoma\n",
       "94242     Unrescetable Hepatocellular Carcinoma\n",
       "Name: Conditions, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some sample Conditions\n",
    "df['Conditions'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a849542e",
   "metadata": {},
   "source": [
    "The below code splits Condition on the vertical bar delimiter ( | ), explodes into one row per condition, cleans up formatting issues, and drops any created blank results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3b16ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_cond_df = (df[['NCT Number', 'Conditions']].dropna(subset=['Conditions']).assign(Condition=lambda d: d['Conditions'].str.split(r\"\\|\")).explode('Condition'))\n",
    "\n",
    "long_cond_df['Condition'] = (long_cond_df['Condition'].astype(str).str.strip()\n",
    "                             .str.replace(r\"\\s+\", \" \", regex=True) # normalize whitespace\n",
    "                             .str.replace(r\"\\.$\", \"\", regex=True)) # remove trailing period\n",
    "\n",
    "# Drop blanks\n",
    "long_cond_df = long_cond_df[long_cond_df['Condition'].ne(\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0eb43a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-deuplicate in case the same condition appears twice in one trial\n",
    "long_cond_df = long_cond_df.drop_duplicates(subset=['NCT Number', 'Condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b4e4eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition\n",
       "healthy                       6459\n",
       "breast cancer                 3566\n",
       "healthy volunteers            1938\n",
       "prostate cancer               1893\n",
       "pain                          1805\n",
       "diabetes mellitus, type 2     1786\n",
       "asthma                        1776\n",
       "multiple myeloma              1713\n",
       "hypertension                  1609\n",
       "hiv infections                1583\n",
       "schizophrenia                 1530\n",
       "colorectal cancer             1522\n",
       "lymphoma                      1499\n",
       "covid-19                      1497\n",
       "non-small cell lung cancer    1412\n",
       "obesity                       1380\n",
       "rheumatoid arthritis          1370\n",
       "ovarian cancer                1273\n",
       "lung cancer                   1230\n",
       "leukemia                      1212\n",
       "type 2 diabetes mellitus      1186\n",
       "cancer                        1159\n",
       "acute myeloid leukemia        1104\n",
       "pancreatic cancer             1089\n",
       "influenza                     1076\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip Condition of whitespaces and transform to lowercase\n",
    "long_cond_df['Condition'] = (long_cond_df['Condition'].str.strip().str.lower())\n",
    "\n",
    "# Investigate what the top conditions are across clinical trials\n",
    "top_conditions = long_cond_df['Condition'].value_counts().head(25)\n",
    "\n",
    "top_conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15c530",
   "metadata": {},
   "source": [
    "In the 04_analysis notebook, filtering Conditions will be done by matching portions of text to capture related conditions with differing phrasing. For example, filter on 'diabetes mellitus' to capture both 'type 2 diabetes mellitus' and 'diabetes mellitus, type 2' which are presently separate conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93553536",
   "metadata": {},
   "source": [
    "## 11. Location Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87a73da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(16943)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm missingness\n",
    "df['Locations'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c78c147f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81382             Emergency Department, Nice, 06000, France\n",
       "158399                                                  NaN\n",
       "21963     Centre Hospitalier Universitaire de Québec, Qu...\n",
       "77473     DIACARE, Ahemdabad, Gujarat, 380015, India|Guj...\n",
       "23582     Creighton University Medical Center (including...\n",
       "152165                                                  NaN\n",
       "40105     Royal University Hospital, Saskatoon, Saskatch...\n",
       "Name: Locations, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Locations'].sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3ab7a",
   "metadata": {},
   "source": [
    "No clinical trial rows will be removed due to missing Location data since those trials still contain important information for analyzing other categorical data. Some clinical trials are performed across multiple Locations, and the sample output above shows that the Country of the trial location is often the last word(s) within the data. \n",
    "\n",
    "The below code splits Location on the vertical bar delimiter ( | ), explodes into one row per condition, cleans up formatting issues, and drops any created blank results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcc2dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_loc_df = (df[['NCT Number', 'Locations']].dropna(subset=['Locations']).assign(Location=lambda d: d['Locations'].str.split(r\"\\|\")).explode('Location'))\n",
    "\n",
    "long_loc_df['Location'] = (long_loc_df['Location'].astype(str).str.strip()\n",
    "                             .str.replace(r\"\\s+\", \" \", regex=True) # normalize whitespace\n",
    "                             .str.replace(r\"\\.$\", \"\", regex=True)) # remove trailing period\n",
    "\n",
    "# Drop blanks\n",
    "long_loc_df = long_loc_df[long_loc_df['Location'].ne(\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e35cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate Location on Country by extracting words after the last comma\n",
    "long_loc_df['Country'] = (long_loc_df['Location'].str.split(',').str[-1].str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cf517715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-deuplicate in case the same Country appears twice in one trial\n",
    "long_loc_df = long_loc_df.drop_duplicates(subset=['NCT Number', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ef834ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NCT Number</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125945</th>\n",
       "      <td>NCT06529185</td>\n",
       "      <td>Egypt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130747</th>\n",
       "      <td>NCT01625182</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167121</th>\n",
       "      <td>NCT05583006</td>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173143</th>\n",
       "      <td>NCT03691831</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7417</th>\n",
       "      <td>NCT05562830</td>\n",
       "      <td>Denmark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137528</th>\n",
       "      <td>NCT00457691</td>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179394</th>\n",
       "      <td>NCT01164891</td>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113275</th>\n",
       "      <td>NCT04139395</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90784</th>\n",
       "      <td>NCT01968954</td>\n",
       "      <td>South Korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196191</th>\n",
       "      <td>NCT00501566</td>\n",
       "      <td>Romania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NCT Number        Country\n",
       "125945  NCT06529185          Egypt\n",
       "130747  NCT01625182          Japan\n",
       "167121  NCT05583006         Taiwan\n",
       "173143  NCT03691831  United States\n",
       "7417    NCT05562830        Denmark\n",
       "137528  NCT00457691        Belgium\n",
       "179394  NCT01164891    Switzerland\n",
       "113275  NCT04139395  United States\n",
       "90784   NCT01968954    South Korea\n",
       "196191  NCT00501566        Romania"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a sample of extracted Country values\n",
    "long_loc_df[['NCT Number', 'Country']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d27575",
   "metadata": {},
   "source": [
    "The Country of each clinical trial's location has been successfully extracted and input into a long format table long_loc_df, to be used for analysis in the 04_analysis notebook. Country names are converted to lowercase below for consistency in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5fa8ff72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country\n",
       "united states     89553\n",
       "china             25037\n",
       "canada            15939\n",
       "germany           15807\n",
       "france            15794\n",
       "united kingdom    14434\n",
       "spain             13067\n",
       "italy             11714\n",
       "south korea       10895\n",
       "australia          9074\n",
       "belgium            8403\n",
       "poland             8154\n",
       "netherlands        7845\n",
       "japan              7387\n",
       "taiwan             5606\n",
       "brazil             5402\n",
       "russia             5386\n",
       "denmark            5316\n",
       "israel             5288\n",
       "czechia            4990\n",
       "hungary            4810\n",
       "egypt              4694\n",
       "sweden             4453\n",
       "austria            4368\n",
       "switzerland        4133\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip Country of whitespaces and transform to lowercase\n",
    "long_loc_df['Country'] = (long_loc_df['Country'].str.strip().str.lower())\n",
    "\n",
    "# Investigate what the top Countries are across clinical trials\n",
    "top_countries = long_loc_df['Country'].value_counts().head(25)\n",
    "\n",
    "top_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a74e17",
   "metadata": {},
   "source": [
    "## 12. Enrollment Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6c182f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(2226)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm missingness\n",
    "df['Enrollment'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d6477ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182267     30.0\n",
       "109389    383.0\n",
       "66452      10.0\n",
       "142112     20.0\n",
       "96614     450.0\n",
       "Name: Enrollment, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show sample of enrollment values\n",
    "df['Enrollment'].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72026ff7",
   "metadata": {},
   "source": [
    "Enrollment data is missing for approximately 1% of the trials (2,226 trials missing data, of remaining 211,711 trials). No trials will be removed due to missing Enrollment data since those trials still contain important information for analyzing other categorical data. The enrollment values currently exist as float datatype, but will be converted to integers since all values for trial enrollments should be whole numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64f3fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast enrollment values to integers (whole numbers)\n",
    "df['Enrollment'] = df['Enrollment'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e946401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Enrollment\n",
       "0      7593\n",
       "30     6226\n",
       "60     5774\n",
       "20     5601\n",
       "40     5509\n",
       "50     4094\n",
       "100    4079\n",
       "24     3920\n",
       "12     3237\n",
       "10     3222\n",
       "80     2737\n",
       "120    2476\n",
       "18     2415\n",
       "15     2406\n",
       "36     2360\n",
       "16     2264\n",
       "200    2238\n",
       "32     2121\n",
       "25     2090\n",
       "48     1997\n",
       "6      1875\n",
       "90     1820\n",
       "150    1688\n",
       "28     1615\n",
       "8      1613\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Investigate what the top Enrollment counts are across clinical trials\n",
    "top_enrollments = df['Enrollment'].value_counts().head(25)\n",
    "\n",
    "top_enrollments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9abc928",
   "metadata": {},
   "source": [
    "Enrollment values of zero indicate trials that have been withdrawn or terminated. The Enrollment category is now ready for use in the  04_analysis notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d839f5",
   "metadata": {},
   "source": [
    "## 13. Final Checks and Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc77fe",
   "metadata": {},
   "source": [
    "This notebook performed the main cleaning and transformations required to enable a successful analysis of the ClinicalTrials.gov dataset, in the context of investigating global drug development patterns. The original dataframe `df` contained multiple forms of messy or inconsistent data, including missing values, mixed data types, and columns that had one-to-many relationships (Interventions, Conditions, and Locations).\n",
    "\n",
    "Key cleaning steps included standardizing date fields, validating enrollment values, normalizing categorical variables, removing irrelevant columns, and handling columns with multiple values that required further parsing for detailed analysis. The most significant transformations involved normalizing the Interventions, Conditions, and Locations columns into three separate long format tables, details of which are shown below in this section. The resulting processed dataset `df` preserves the original data structure while establishing consistent types, formats, and assumptions, providing a basis for analysis in later notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b67609",
   "metadata": {},
   "source": [
    "## Outputs & Handoff to 04_analysis\n",
    "\n",
    "This notebook produces four cleaned datasets used as inputs to `04_analysis.ipynb`:\n",
    "\n",
    "- **Trial-level dataset (`df`)** is the primary dataframe for analysis, and is based on one row per clinical trial with unique `NCT Number`.\n",
    "- **Interventions (`long_inter_df`)** normalized the `Interventions` field into a long format, with one row per intervention per trial.\n",
    "- **Conditions (`long_cond_df`)** normalized the `Conditions` field into a long format, with one row per condition per trial.\n",
    "- **Locations (`long_loc_df`)** normalized the `Locations` field into a long format, with one row per location per trial, with country extracted.\n",
    "\n",
    "Data Dictionaries for each of the four cleaned datasets are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e71557",
   "metadata": {},
   "source": [
    "## Final Cleaned Trial-Level Dataset (`df`) — Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f21d5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dateframe: df\n",
      "rows: 211770 cols: 12\n"
     ]
    }
   ],
   "source": [
    "print('Dateframe: df')\n",
    "print('rows:', df.shape[0], 'cols:', df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe9ea79",
   "metadata": {},
   "source": [
    "| Column | Description |\n",
    "|---|---|\n",
    "| `NCT Number` | Unique ClinicalTrials.gov identifier for each trial (primary key). |\n",
    "| `Conditions` | Pipe-delimited list of conditions/diseases studied in the trial (raw text, preserved). |\n",
    "| `Interventions` | Pipe-delimited list of intervention strings as reported in ClinicalTrials.gov (raw text, preserved). |\n",
    "| `Sponsor` | Lead sponsor organization responsible for the trial. |\n",
    "| `Phases` | Clinical trial phase(s) (cleaned and standardized text). |\n",
    "| `Enrollment` | Planned or actual number of participants enrolled (numeric, non-negative). |\n",
    "| `Funder Type` | Categorized funding source (e.g., Industry, NIH, Other). |\n",
    "| `Study Type` | Type of study (e.g., Interventional, Observational). |\n",
    "| `Start Date` | Trial start date (parsed to datetime where possible). |\n",
    "| `Primary Completion Date` | Date of final data collection for the primary outcome measure. |\n",
    "| `Locations` | Pipe-delimited list of study site locations as reported. |\n",
    "| `drug_bio_interventions` | List of unique DRUG and/or BIOLOGICAL intervention names associated with the trial (derived from normalized intervention data). |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a793b9b6",
   "metadata": {},
   "source": [
    "## Normalized Intervention-Level Dataset (`long_inter_df`) — Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e1201028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dateframe: long_inter_df\n",
      "rows: 901606 cols: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NCT Number', 'Interventions', 'Intervention_Class', 'Intervention_Name']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dateframe: long_inter_df')\n",
    "print('rows:', long_inter_df.shape[0], 'cols:', long_inter_df.shape[1])\n",
    "long_inter_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b34b22",
   "metadata": {},
   "source": [
    "| Column | Description |\n",
    "|---|---|\n",
    "| `NCT Number` | Trial identifier (foreign key linking back to the trial-level `df`). |\n",
    "| `Interventions` | Original interventions string from the trial-level dataset `df`. |\n",
    "| `Intervention_Class` | Intervention type (e.g., `DRUG`, `BIOLOGICAL`) using regex. |\n",
    "| `Intervention_Name` | Intervention name extracted from each intervention entry (text after the `:`) and cleaned (trimmed/normalized). |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d84ff3",
   "metadata": {},
   "source": [
    "## Normalized Condition-Level Dataset (`long_cond_df`) — Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a04d1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: long_cond_df\n",
      "rows: 362657 cols: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NCT Number', 'Conditions', 'Condition']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dataframe: long_cond_df')\n",
    "print('rows:', long_cond_df.shape[0], 'cols:', long_cond_df.shape[1])\n",
    "long_cond_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251ba881",
   "metadata": {},
   "source": [
    "| Column | Description |\n",
    "|---|---|\n",
    "| `NCT Number` | Trial identifier (foreign key linking back to the trial-level `df`). |\n",
    "| `Conditions` | Original conditions string from the trial-level dataset `df`. |\n",
    "| `Condition` | Individual condition value derived by splitting `Conditions`. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc751ea",
   "metadata": {},
   "source": [
    "## Normalized Location-Level Dataset (`long_loc_df`) — Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d0d49c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: long_loc_df\n",
      "rows: 385273 cols: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NCT Number', 'Locations', 'Location', 'Country']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dataframe: long_loc_df')\n",
    "print('rows:', long_loc_df.shape[0], 'cols:', long_loc_df.shape[1])\n",
    "long_loc_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cec2fc",
   "metadata": {},
   "source": [
    "| Column | Description |\n",
    "|---|---|\n",
    "| `NCT Number` | Trial identifier (foreign key linking back to the trial-level `df`). |\n",
    "| `Locations` | Original locations string from the trial-level dataset `df`. |\n",
    "| `Location` | Single location value derived by splitting `Locations`. |\n",
    "| `Country` | Country extracted from `Location`. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895dec25",
   "metadata": {},
   "source": [
    "## 14. Export to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e0402",
   "metadata": {},
   "source": [
    "The three new dataframes and the processed primary dataframe will now be exported to the project's processed data folder for use in the 04_analysis notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94636cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "output_dir = project_root/'data'/'processed'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df.to_csv(output_dir/'clean_trials.csv', index=False)\n",
    "long_inter_df.to_csv(output_dir/'clean_interventions.csv', index=False)\n",
    "long_cond_df.to_csv(output_dir/'clean_conditions.csv', index=False)\n",
    "long_loc_df.to_csv(output_dir/'clean_locations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
